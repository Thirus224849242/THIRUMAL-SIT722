name: CD ‚Äì Staging Deploy & Teardown

on:
  workflow_run:
    workflows: ["CI Test, Build & Push to ACR (testing branch)"]
    types:
      - completed

jobs:
  deploy-staging:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Set up kubectl
        uses: azure/setup-kubectl@v3

      - name: Get AKS Credentials
        run: |
          az aks get-credentials \
            --name ${{ secrets.AKS_CLUSTER_NAME }} \
            --resource-group ${{ secrets.AKS_RESOURCE_GROUP }} \
            --overwrite-existing

      - name: Create staging namespace
        run: |
          kubectl create namespace staging --dry-run=client -o yaml | kubectl apply -f -

      - name: Apply configs & secrets
        run: |
          kubectl apply -n staging -f k8s/configmaps.yaml || true
          kubectl apply -n staging -f k8s/secrets.yaml || true

      - name: Deploy to staging
        run: |
          kubectl apply -n staging -f k8s/

      - name: Wait for Pods to be Ready (with retries & debug)
        run: |
          set +e
          for i in {1..8}; do
            echo "üîÑ Attempt $i to wait for deployments..."
            kubectl wait --for=condition=available --timeout=90s deployment --all -n staging
            STATUS=$?
            if [ $STATUS -eq 0 ]; then
              echo "‚úÖ All deployments are available!"
              exit 0
            fi
            echo "‚ùå Pods not ready yet. Dumping debug info..."
            echo "----- Pods -----"
            kubectl get pods -n staging -o wide
            echo "----- Deployments -----"
            kubectl get deploy -n staging
            echo "----- Events -----"
            kubectl get events -n staging --sort-by=.lastTimestamp | tail -n 20
            for pod in $(kubectl get pods -n staging -o jsonpath='{.items[*].metadata.name}'); do
              echo "--- Describe $pod ---"
              kubectl describe pod $pod -n staging || true
              echo "--- Last 50 logs for $pod ---"
              kubectl logs $pod -n staging --tail=50 || true
            done
            echo "Retrying in 60s..."
            sleep 60
          done
          exit 1

      - name: Smoke Test Services (with IP retry)
        run: |
          echo "üîç Waiting for frontend LoadBalancer IP..."
          for i in {1..10}; do
            FRONTEND_IP=$(kubectl get svc frontend-service -n staging -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
            if [ -n "$FRONTEND_IP" ]; then
              echo "‚úÖ Frontend IP acquired: $FRONTEND_IP"
              curl -s http://$FRONTEND_IP/health && exit 0
            fi
            echo "‚ö†Ô∏è No IP yet, retrying in 30s... (attempt $i)"
            sleep 30
          done
          echo "‚ùå Frontend IP not assigned after waiting."
          kubectl get svc -n staging
          exit 1

  # üõë Teardown job, runs after staging is tested
  teardown-staging:
    needs: deploy-staging
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Set up kubectl
        uses: azure/setup-kubectl@v3

      - name: Get AKS Credentials
        run: |
          az aks get-credentials \
            --name ${{ secrets.AKS_CLUSTER_NAME }} \
            --resource-group ${{ secrets.AKS_RESOURCE_GROUP }} \
            --overwrite-existing

      - name: Delete staging namespace
        run: kubectl delete namespace staging --ignore-not-found
